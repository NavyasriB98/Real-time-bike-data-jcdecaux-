{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b33fd2c",
   "metadata": {},
   "source": [
    "# Programming for Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a79201",
   "metadata": {},
   "source": [
    "### Collection and Analysis of real time bike data for different cities using JCDecaux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f07c01",
   "metadata": {},
   "source": [
    "#### Group: Navyasri Biruda(K00290652) & Riji Mary Thomas(K00290671) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72053ae8",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b023787b",
   "metadata": {},
   "source": [
    "#### The primary task was to pull down real-time bike data from JCDecaux. A scheduler that was set to run every hour was used to collect the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f88dc3",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a28ac2",
   "metadata": {},
   "source": [
    "* Analyzing the patterns of bike usage in a few chosen cities\n",
    "* Analysing bike usage over weekdays and weekends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40079c1b",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217feb3b",
   "metadata": {},
   "source": [
    "1. JCDecaux Website is used to get the data in real time\n",
    "2. Data preprocessing is done\n",
    "3. Dividing the days into weekdays and weekends to analyse trends\n",
    "4. Dividing hour of day into morning and evening to analyse trends\n",
    "5. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bfa81a",
   "metadata": {},
   "source": [
    "# Loading data and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb81db1",
   "metadata": {},
   "source": [
    "The data collected from JCDecaux has  rows.\n",
    "\n",
    "The following data is received from JCDecaux API number -station identification number. contractName - the station's contract's name name - the station's name address- the station's address position -the position of the station banking -if the station has terminal for payment, bonus -if the station is a bonus station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95d4731c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bikes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m bike_df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbikes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize of Bike Data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(bike_df))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bikes.csv'"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import time\n",
    "import datetime as dt\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "bike_df=pd.read_csv(\"bikes.csv\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Size of Bike Data\",len(bike_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa59187",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd938f70",
   "metadata": {},
   "source": [
    "We checked for the datatype of bike_df and found that all are in strings, even if numeric columns are also there. Here we changed the datatype to numeric values and for the last_update column to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bccfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns=[\"number\", \"bike_stands\", \"available_bike_stands\", \"available_bikes\"]\n",
    "bike_df[numeric_columns]=bike_df[numeric_columns].apply(lambda x : pd.to_numeric(x, errors='coerce'))\n",
    "bike_df[\"last_update\"]=pd.to_datetime(bike_df['last_update'], unit='ms', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115f3ce",
   "metadata": {},
   "source": [
    "Next we are checking for redundant values & removing the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Duplicates and Handle Incorrect Data\n",
    "bike_df.drop_duplicates(inplace=True)\n",
    "df.isna(bike_df).sum()\n",
    "bike_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2f71d",
   "metadata": {},
   "source": [
    "since we have cleaned our data, we can continue with our analysis. Using describe() functions we found the summary statistics for the bike data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1702c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cd55a",
   "metadata": {},
   "source": [
    "For making analysis easier and understandable we are using feature engineering. We have created features called **Day** and **Usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af19a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df['Day']=bike_df['last_update'].dt.day_name()\n",
    "bike_df['Day']=bike_df['Day'].astype(str)\n",
    "bike_df['hour'] = bike_df['last_update'].dt.time\n",
    "\n",
    "\n",
    "\n",
    "bike_df['usage'] = np.where(bike_df['available_bikes'] >= bike_df['bike_stands'] // 2, 'Low', 'High')\n",
    "\n",
    "#In this code, we use the `np.where` function from the `numpy` library to create the \"usage\" column based on the condition. If the condition `bike_csv[\"available_bikes\"] >= bike_csv[\"bike_stands\"] // 2` is true, it assigns \"Low\" to the \"usage\" column, otherwise \"High\" is assigned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8633da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0708ca7e",
   "metadata": {},
   "source": [
    "We can check for the total bike stands per city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be560161",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bike_stands_city=bike_df.groupby('contract_name')['bike_stands'].sum()\n",
    "print(total_bike_stands_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7862474",
   "metadata": {},
   "source": [
    "This will show the total number of bike stands for each city in the dataset. **Bruxelles** have the highest and **jcdecauxbike ** has the least number of bike stands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c76b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the average number of bikes rented per day for each city\n",
    "avg_bikes_rented_by_city = bike_df.groupby('contract_name')['available_bikes'].max()\n",
    "print( avg_bikes_rented_by_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde577e",
   "metadata": {},
   "source": [
    "Next, we can check for the peak time per city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287063be",
   "metadata": {},
   "outputs": [],
   "source": [
    "busiest_times_by_city = bike_df.groupby('contract_name')['last_update'].value_counts().groupby(level=0).head(1)\n",
    "print(busiest_times_by_city)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8fe5b",
   "metadata": {},
   "source": [
    "From the output, its showing that, 2023-12-11 20:22:53.696 is the highest bike usage time for the city Bruxelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usage_location=bike_df.groupby('position')['available_bikes'].sum().reset_index(name='usage_count')\n",
    "#max_position = usage_location.loc[usage_location['usage_count'].idxmax()]['position']\n",
    "#print(\"Latitude with highest usage:\", max_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b636c5",
   "metadata": {},
   "source": [
    "We are going to analyse the dublin contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc37e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_dataset=bike_df[bike_df['contract_name']==\"dublin\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f687319",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dublin_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dublin_dataset\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dublin_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dublin_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d591757",
   "metadata": {},
   "source": [
    "We need to  to find out which day was busy and which day of week was not busy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5368ae3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dublin_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#1)to calculate which day of week has more bikes available and less bikes available.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m avail_bikes_day \u001b[38;5;241m=\u001b[39m dublin_dataset\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable_bikes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      3\u001b[0m Day_max_bike \u001b[38;5;241m=\u001b[39m avail_bikes_day\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[0;32m      4\u001b[0m Day_min_bike \u001b[38;5;241m=\u001b[39m avail_bikes_day\u001b[38;5;241m.\u001b[39midxmin()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dublin_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#1)to calculate which day of week has more bikes available and less bikes available.\n",
    "avail_bikes_day = dublin_dataset.groupby('Day')['available_bikes'].sum()\n",
    "Day_max_bike = avail_bikes_day.idxmax()\n",
    "Day_min_bike = avail_bikes_day.idxmin()\n",
    "print(f\"The day of week with the most available bikes is: {Day_max_bike}\")\n",
    "print(f\"The day of week with the least available bikes is: {Day_min_bike}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d11f599",
   "metadata": {},
   "source": [
    "From the output we can say that Thursday has the highest avaialable bikes and least bikes in Friday."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96f5ba0",
   "metadata": {},
   "source": [
    "We checked for three peak hours and three days having highest bike usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb327569",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dublin_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#2) Peak hours and days of bike usage\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m peak_Day_Time \u001b[38;5;241m=\u001b[39m dublin_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhour\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Get the top 5 peak hours\u001b[39;00m\n\u001b[0;32m      4\u001b[0m peak_days \u001b[38;5;241m=\u001b[39m dublin_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_update\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday_name()\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Get the top 5 peak days\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPeak_Hours\u001b[39m\u001b[38;5;124m\"\u001b[39m, peak_Day_Time)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dublin_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#2) Peak hours and days of bike usage\n",
    "\n",
    "peak_Day_Time = dublin_dataset['hour'].value_counts().nlargest(3)  # Get the top 5 peak hours\n",
    "peak_days = dublin_dataset['last_update'].dt.day_name().value_counts().nlargest(3)  # Get the top 5 peak days\n",
    "print(\"Peak_Hours\", peak_Day_Time)\n",
    "print(\"peak_days\", peak_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a785fc",
   "metadata": {},
   "source": [
    "Analysing the output, we can see the three peak date with time and the days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19f2d3",
   "metadata": {},
   "source": [
    "Next, we compared the average bike usage over weekday and weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e482e015",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#3) weekend compared with weekdays bases on bike usage.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m weekday_weekend \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[0;32m      3\u001b[0m     (dublin_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSunday\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m|\u001b[39m (dublin_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaturday\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekend\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekday\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m )\u001b[38;5;66;03m#Usage weekday vs weekend\u001b[39;00m\n\u001b[0;32m      7\u001b[0m week_group \u001b[38;5;241m=\u001b[39m dublin_dataset\u001b[38;5;241m.\u001b[39mgroupby(weekday_weekend)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#week_group.first()\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#3) weekend compared with weekdays bases on bike usage.\n",
    "weekday_weekend = np.where(\n",
    "    (dublin_dataset['Day'] == 'Sunday') | (dublin_dataset['Day'] == 'Saturday'),\n",
    "    'Weekend',\n",
    "    'Weekday'\n",
    ")#Usage weekday vs weekend\n",
    "week_group = dublin_dataset.groupby(weekday_weekend)\n",
    "#week_group.first()\n",
    "print(\"Average Usage during Weekend \",week_group.get_group('Weekend')['available_bike_stands'].mean())\n",
    "print(\"Average Usage during Weekday \",week_group.get_group('Weekday')['available_bike_stands'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f370a",
   "metadata": {},
   "source": [
    "We can say that the average usage in weeday is slighly higher than weekend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fd87b",
   "metadata": {},
   "source": [
    "We checked for which stations is offering banking facility without any bonuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8a69a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dublin_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# #4)Check if a station offers banking services without bonuses\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m banking_without_bonus \u001b[38;5;241m=\u001b[39m dublin_dataset[(dublin_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbanking\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m ) \u001b[38;5;241m&\u001b[39m (dublin_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbonus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Display the addresses where only banking is available without a bonus\u001b[39;00m\n\u001b[0;32m      5\u001b[0m station_addresses \u001b[38;5;241m=\u001b[39m banking_without_bonus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dublin_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# #4)Check if a station offers banking services without bonuses\n",
    "banking_without_bonus = dublin_dataset[(dublin_dataset['banking'] == True ) & (dublin_dataset['bonus'] == False)]\n",
    "\n",
    "# Display the addresses where only banking is available without a bonus\n",
    "station_addresses = banking_without_bonus['name']\n",
    "print(\"Stations offering only banking without a bonus:\")\n",
    "print(station_addresses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b460c5",
   "metadata": {},
   "source": [
    "After analysing the output we can say that the above five stations are offering banking facility without any bonuses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d49ca",
   "metadata": {},
   "source": [
    "we checked for  total amount of bikes and bike stands available in all the stations in dublin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd6a74d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dublin_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#5) availabilty of total bikes and bike stands accross all different stations.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m station_total \u001b[38;5;241m=\u001b[39m dublin_dataset\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable_bikes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable_bike_stands\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe total number ofstations\u001b[39m\u001b[38;5;124m\"\u001b[39m, station_total)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dublin_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#5) availabilty of total bikes and bike stands accross all different stations.\n",
    "station_total = dublin_dataset.groupby('name').agg({'available_bikes': 'sum', 'available_bike_stands': 'sum'})\n",
    "\n",
    "print(\"the total number ofstations\", station_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faf508b",
   "metadata": {},
   "source": [
    "we have checked for the stations with highest and lowest bike stands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a64ca458",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dublin_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#6)stations with highest and lowest bike stands\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m avail_bikes_stands \u001b[38;5;241m=\u001b[39m dublin_dataset\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbike_stands\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      3\u001b[0m max_bike_stand \u001b[38;5;241m=\u001b[39m avail_bikes_stands\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m      4\u001b[0m min_bike_stand \u001b[38;5;241m=\u001b[39m avail_bikes_stands\u001b[38;5;241m.\u001b[39mmin()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dublin_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#6)stations with highest and lowest bike stands\n",
    "avail_bikes_stands = dublin_dataset.groupby('name')['bike_stands'].sum()\n",
    "max_bike_stand = avail_bikes_stands.max()\n",
    "min_bike_stand = avail_bikes_stands.min()\n",
    "station_name_high = avail_bikes_stands.idxmax()\n",
    "station_name_low = avail_bikes_stands.idxmin()\n",
    "print(f\"The highest num of bikes stands is: {max_bike_stand} with station name {station_name_high}\")\n",
    "print(f\"The lowest num of bikes stands is: {min_bike_stand}with station name {station_name_low}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a658fa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1740122695.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    In this section we analysed that the station benson street has the highest number of bikes stand and the dame street\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "In this section we analysed that the station benson street has the highest number of bikes stand and the dame street \n",
    "has the lowest number of bike stands ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764cf10a",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61721a82",
   "metadata": {},
   "source": [
    "In this analysis we have found insights on dublin city by using live bikes dataset which we have extracted.After a thorough examination of Dublin's bike usage data, a number of important conclusions were drawn. The analysis helped to determine the times of highest bike utilization, examine how bike usage varies on weekdays and weekends, investigate station facilities with banking and without bonuses, and assess the general availability of bikes and bike stands around the city. \n",
    "  \n",
    "The study revealed that the times when there is the greatest demand for bike services by identifying three peak hours and three busiest days based on bike usage. Increasing services and allocating resources are made easier with this insight. \n",
    "\n",
    "Slight differences in user behavior were revealed by comparing bike riding on weekdays and weekends. Identifying these variations can help in customizing services to better suit varied usage patterns on different days of the week.\n",
    "\n",
    "Finding the stations with the greatest and lowest bike stands, The station with highest might be able to hold more bikes for users because it probably has more space for parking bikes and vice versa.\n",
    "\n",
    "In general, bike usage is dependent on the city because if we are checking for any other city the peak days and all the conclusion may vary."
   ]
  },
  {

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d4e350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1d029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
